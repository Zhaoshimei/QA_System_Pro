{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- enviroment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import spacy\n",
    "from scipy import spatial\n",
    "import json\n",
    "import numpy as np\n",
    "import nltk\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim import models\n",
    "import string\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from collections import defaultdict\n",
    "from math import log\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from nltk.tag import StanfordNERTagger\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import urllib\n",
    "import sys\n",
    "import os\n",
    "import zipfile\n",
    "import tarfile\n",
    " \n",
    "import hashlib\n",
    "import re\n",
    "import itertools\n",
    "from sklearn import metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = \"/Users/alfredchen/Documents/GitHub/query-system/data/training.json\"\n",
    "dev_set = \"/Users/alfredchen/Documents/GitHub/query-system/data/devel.json\"\n",
    "test_set = \"/Users/alfredchen/Documents/GitHub/query-system/data/testing.json\"\n",
    "doc = \"/Users/alfredchen/Documents/GitHub/query-system/data/documents.json\"\n",
    "\n",
    "#save word embeddings\n",
    "embeddings = \"/Users/alfredchen/Documents/GitHub/query-system/models/mymodel-size\"\n",
    "\n",
    "# save qa log\n",
    "log_file = \"/Users/alfredchen/Documents/GitHub/query-system/data/log.txt\"\n",
    "answer_type_file = \"/Users/alfredchen/Documents/GitHub/query-system/data/answer_type_label.txt\"\n",
    "topk_file = \"/Users/alfredchen/Documents/GitHub/query-system/data/topk.json\"\n",
    "answer_file = \"/Users/alfredchen/Documents/GitHub/query-system/data/answer.txt\"\n",
    "ner_jar = \"/Users/alfredchen/Documents/GitHub/query-system/data/stanford-ner.jar\"\n",
    "ner_model = \"/Users/alfredchen/Documents/GitHub/query-system/data/english.muc.7class.distsim.crf.ser.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- preprocess corpus\n",
    "    - remove stopwords\n",
    "    - lemmatize\n",
    "    - lower case\n",
    "    - creat paragraph_index\n",
    "    - create index2paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_stopwords(flag):\n",
    "        \n",
    "        words = list(nltk.corpus.stopwords.words())\n",
    "        \n",
    "        if flag == False:\n",
    "        #some stopwords are helpful in targeting answer type, shall not be removed\n",
    "            words.remove('what')\n",
    "            words.remove('where')\n",
    "            words.remove('when')\n",
    "            words.remove('who')\n",
    "            words.remove('how')\n",
    "            words.remove('which')\n",
    "        # add more #\n",
    "\n",
    "        stopwords = {}\n",
    "        for word in words:\n",
    "            stopwords[word] = stopwords.get(word,0) + 1\n",
    "        return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word, 'v')\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word, 'n')\n",
    "    return lemma\n",
    "\n",
    "def removePunc(string):\n",
    "    # define punctuation\n",
    "    punctuations = '''!()-[]{};:'\"\\,./?@#$%^&*_~'''\n",
    "    \n",
    "    # remove punctuation from the string\n",
    "    no_punct = \"\"\n",
    "    for char in string:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char\n",
    "\n",
    "    # display the unpunctuated string\n",
    "    #print(no_punct)\n",
    "    return no_punct\n",
    "\n",
    "\n",
    "stopwords = get_stopwords(True)        # get stopwords\n",
    "\n",
    "def preprocess_docs(corpus):\n",
    "        para2index = {}\n",
    "        index2para = {}\n",
    "        new_corpus = []\n",
    "        para_len = 0\n",
    "        para_count = 0\n",
    "        for _id, doc in enumerate(corpus):\n",
    "            new_doc = []\n",
    "            for _para,para in enumerate(doc['text']):\n",
    "                para2index[para] = (_id,_para)         # para index\n",
    "                index2para[(_id,_para)] = para         # doc_id, answer_para index\n",
    "                new_para = []\n",
    "                sents = para.split('.')\n",
    "                para_count += 1\n",
    "                for _sent,sent in enumerate(sents):\n",
    "                    new_sent=[]\n",
    "                    sent = removePunc(sent)\n",
    "                    #sent = '<s> ' + sent + ' <end>'  # padding\n",
    "                    words = sent.split(' ')\n",
    "                    s = ''.join(sent)\n",
    "                    if s == '<s> <end>':\n",
    "                        continue\n",
    "                    for word in words:\n",
    "                        word = word.strip(',')\n",
    "                        word = word.strip(',')\n",
    "                        word = word.strip('.')\n",
    "                        word = word.strip('?')\n",
    "                        word = word.strip('\\'s')\n",
    "                        word = word.strip('\\\"')\n",
    "                            #if not word.isalpha():\n",
    "                                #continue\n",
    "                        new_word = word.lower()\n",
    "                        new_word = lemmatize(new_word)\n",
    "                        if stopwords.get(new_word):\n",
    "                            continue\n",
    "                        if new_word == '':\n",
    "                            continue\n",
    "                        para_len += 1\n",
    "                        new_sent.append(new_word)                \n",
    "                    new_para.append(new_sent)\n",
    "                new_doc.append(new_para)\n",
    "            new_corpus.append(new_doc)\n",
    "        average_para_len = (para_len/para_count)\n",
    "        print(average_para_len)\n",
    "        return new_corpus, para2index, index2para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.1837880794702\n"
     ]
    }
   ],
   "source": [
    "docs = json.load(open(doc))\n",
    "corpus,para2index,index2para = preprocess_docs(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get word embeddings based on pre processed corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def w2v(corpora,size,iter):\n",
    "        docs = corpora\n",
    "        sentences = []\n",
    "        for doc in docs:\n",
    "            for sents in doc:\n",
    "                new_para = []\n",
    "                for sent in sents:\n",
    "                    new_para += sent\n",
    "                sentences.append(new_para)\n",
    "        model = Word2Vec(sentences, size=size, window=5,iter=iter,workers=4)\n",
    "        model.save(embeddings+str(size)+'-iter'+str(iter))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = w2v(corpus,160,150)   # train the model\n",
    "\n",
    "#load pre-trained model\n",
    "model = gensim.models.Word2Vec.load(embeddings+str(160)+'-iter'+str(150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_freqs(corpus):\n",
    "    tfs = defaultdict(dict)\n",
    "    tfs_forward = defaultdict(dict)\n",
    "    doc_id = 0\n",
    "    for doc in corpus:\n",
    "        for para in doc:\n",
    "            for sent in para:\n",
    "                for term in sent:\n",
    "                    tfs[term][doc_id] = tfs[term].get(doc_id, 0) + 1 \n",
    "                    tfs_forward[doc_id][term] = tfs[doc_id].get(term, 0) + 1\n",
    "        doc_id += 1\n",
    "    return tfs,doc_id+1,tfs_forward\n",
    "\n",
    "\n",
    "tfs,total_docment,tfs_forward = term_freqs(corpus)\n",
    "\n",
    "def get_tfidf(tfs, total_docment,tfs_forward):\n",
    "    document_length = {}\n",
    "    for doc_id,doc_list in tfs_forward.items():\n",
    "        length = 0\n",
    "        for term, freq in doc_list.items():\n",
    "            length += freq ** 2\n",
    "        length = length **0.5\n",
    "        document_length[doc_id] = length\n",
    "    tfidf = defaultdict(dict)\n",
    "    for term, doc_list in tfs.items():\n",
    "        df = len(doc_list)\n",
    "        for doc_id, freq in doc_list.items(): \n",
    "            tfidf[term][doc_id] = (float(tfs[term][doc_id]) * log(total_docment / df)) / document_length.get(doc_id)\n",
    "    return tfidf\n",
    "\n",
    "tfidf = get_tfidf(tfs, total_docment,tfs_forward)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- transform sentence to feature vector (sentence embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    def get_weight(word,doc_id):\n",
    "        try:\n",
    "            weight = tfidf[word][doc_id]\n",
    "        except KeyError:\n",
    "            weight = 0.0001\n",
    "        return weight \n",
    "    \n",
    "    def sent2vec(sentence, model, size, index2word_set, doc_id):\n",
    "        \"\"\"transform word embeddings to sentence vector\n",
    "        param: sentence: sentence that want to be transformed\n",
    "        param: model: pre-trained word embeddings\n",
    "        param: size: feature vector dimension\n",
    "        param: index2word_set\n",
    "        return: transformed sentence vector\n",
    "        \"\"\"        \n",
    "        try:\n",
    "            words = sentence.split()  \n",
    "        except:\n",
    "            words = sentence\n",
    "        \n",
    "        try:\n",
    "            words = [removePunc(x) for x in words]\n",
    "        except:\n",
    "            pass\n",
    "        feature_vec = np.zeros((size,), dtype='float32')\n",
    "        n_words = 0\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            word = lemmatize(word)\n",
    "            if stopwords.get(word):\n",
    "                continue\n",
    "            if word in index2word_set:\n",
    "                n_words += 1\n",
    "                if doc_id != 'disable':\n",
    "                    w = get_weight(word,doc_id)\n",
    "                else:\n",
    "                    w = 1\n",
    "                feature_vec = np.add(feature_vec, model.wv[word]*w)\n",
    "        if (n_words > 0):\n",
    "            feature_vec = np.divide(feature_vec, n_words)\n",
    "        return feature_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- play with sentence vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6428887844085693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('king', 0.7751615643501282),\n",
       " ('balmoral', 0.748808741569519),\n",
       " ('duke', 0.7470282912254333),\n",
       " ('fief', 0.7448990941047668),\n",
       " ('royal', 0.7361407279968262),\n",
       " ('lambert', 0.7349075078964233),\n",
       " ('controversially', 0.7227569818496704),\n",
       " ('prince', 0.7206754088401794),\n",
       " ('frederick', 0.7180166244506836),\n",
       " ('elizabeth', 0.7173427939414978)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate similarity of two sentence\n",
    "\n",
    "s1_afv = sent2vec('A kilogram could be definined as having a Planck constant of what value?', model, 160, index2word_set,'disable')\n",
    "s2_afv = sent2vec('Possible new definitions include \"the mass of a body at rest whose equivalent energy equals the energy of photons whose frequencies sum to 7050135639273999999♠135639274×1042 Hz\", or simply \"the kilogram is defined so that the Planck constant equals 6966662606895999999♠6.62606896×10−34 J⋅s\".', model, 160, index2word_set,'disable')\n",
    "sim = 1 - spatial.distance.cosine(s1_afv, s2_afv)\n",
    "print(sim)\n",
    "model.wv.most_similar_cosmul(positive=['male', 'queen'], negative=['female'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get similarity ranking of query to paragraphs in a documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_sent(query, corpus):\n",
    "    sim2ipara = {}\n",
    "    index2sim = {}\n",
    "    for _id,doc in enumerate(corpus):\n",
    "        q = sent2vec(query, model, 160, index2word_set,_id)\n",
    "        for _para,para in enumerate(doc):\n",
    "            sentence = []\n",
    "            for sent in para:\n",
    "                sentence += sent\n",
    "            sentence = sent2vec(sentence, model, 160, index2word_set,'disable')\n",
    "            sim = 1 - spatial.distance.cosine(q, sentence)\n",
    "            index2sim[_id, _para] = sim\n",
    "            sim2ipara[sim] = (_id,_para)\n",
    "    return index2sim, sim2ipara\n",
    "    \n",
    "\n",
    "#index2sim, sim2ipara = sim_sent(\"what does the Planck constant refer to?\",corpus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(query, answer):\n",
    "    sim = 1 - spatial.distance.cosine(query, answer)\n",
    "    return sim\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 5), (0, 1), (0, 16), (0, 13), (0, 23), (0, 11), (0, 17), (0, 2), (0, 10), (0, 0)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def getTopN(N,query,docid):\n",
    "    if docid == 'disable':\n",
    "        top_document_id = Counter()\n",
    "        for token in word_tokenize(query):\n",
    "            token = token.lower()\n",
    "            token = lemmatize(token)\n",
    "            if not stopwords.get(token):\n",
    "                term_tfidf = tfidf[token]\n",
    "                for docid, weight in term_tfidf.items():\n",
    "                     top_document_id[docid] += weight\n",
    "        top_document_id = top_document_id.most_common(N)\n",
    "        top_document = []\n",
    "        for document_id,weight in top_document_id:\n",
    "            top_document.append(document_id)\n",
    "    else:\n",
    "        top_document = [docid]\n",
    "    sim2index = {}\n",
    "    q = sent2vec(query, model, 160, index2word_set,'disable')\n",
    "    \n",
    "    for _id in top_document:\n",
    "        #q = sent2vec(query, model, 160, index2word_set,_id)\n",
    "        paras = [para for (doc,para) in index2para.keys() if doc == _id]\n",
    "        for _para in paras:\n",
    "            answer = index2para.get((_id,_para))\n",
    "            answer = sent2vec(answer, model, 160, index2word_set,'disable')\n",
    "            sim = sentence_similarity(q, answer)\n",
    "            sim2index[sim] = (_id,_para)\n",
    "    \n",
    "    similarity_ranks = sorted(sim2index.keys(),reverse=True)   #sims\n",
    "    rank = []\n",
    "    for i in range(N):\n",
    "        try:\n",
    "            rank.append(sim2index.get(similarity_ranks[i]))\n",
    "        except IndexError as e:\n",
    "            print(top_document_id)\n",
    "    logs_file = open(log_file,\"a\")\n",
    "    logs_file.write(str(rank)+'\\n')\n",
    "    logs_file.close()\n",
    "    return rank\n",
    "    \n",
    "        \n",
    "\n",
    "index = getTopN(10,\n",
    "                \"A kilogram could be definined as having a Planck constant of what value?\",'disable')    \n",
    "print(index)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get top n answer paragraph given quey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def getTopN(N,query):\n",
    "    index2sim, sim2ipara = sim_sent(query,corpus)\n",
    "    \n",
    "    similarity_ranks = sorted(index2sim.values(),reverse=True)   #sims\n",
    "    rank = []\n",
    "    for i in range(N):\n",
    "        rank.append(sim2ipara.get(similarity_ranks[i])) \n",
    "        \n",
    "    return rank\n",
    "    \n",
    "\n",
    "getTopN(10,\"Who developed the theory of inheritance known as pangenesis?\")\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test hit accuracy: return top 10 paragraphs, is given answer included?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gold_standard(dataset):\n",
    "    file = json.load(open(dataset))\n",
    "    gold2index={}\n",
    "    for line in file:\n",
    "        _id = line['docid']\n",
    "        try:\n",
    "            _para = line['answer_paragraph']\n",
    "        except KeyError:\n",
    "            _para = line['id']\n",
    "        gold2index[line['question']]=(_id,_para)\n",
    "    return gold2index\n",
    "\n",
    "def my_qa(n,dataset):\n",
    "    file = json.load(open(dataset))\n",
    "    qa2index={}\n",
    "    for i in range(n):\n",
    "        save = open(log_file,\"a\")\n",
    "        line = file[i]\n",
    "        query = line['question']\n",
    "        possible = getTopN(10,query,line[docid])\n",
    "        qa2index[line['question']] = possible\n",
    "        record = line['question']+':'+str(possible)+'\\n'\n",
    "        save.write(record)\n",
    "        save.close()\n",
    "    return qa2index\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def acc(gold_standard,qas):\n",
    "    query = qas.keys()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i,q in enumerate(query):\n",
    "        gold = gold_standard.get(q)\n",
    "        if gold in qas.get(q):\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    acc = correct/total\n",
    "    return acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#test on top 100 trainset\n",
    "gold_index = gold_standard(train_set)\n",
    "qa_index = my_qa(100,train_set)\n",
    "accu = acc(gold_index,qa_index)\n",
    "print(accu)\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#test on entire devtset\n",
    "gold_index = gold_standard(dev_set)\n",
    "qa_index = my_qa(100,dev_set)\n",
    "acc = acc(gold_index,qa_index)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prepare relevance training data\n",
    "assign label 1 denote relevance, label0 denote irrelevance\n",
    "randomly choose incorrect query-answer pairs in trainset and labeled 0\n",
    "choose top N correct query-answer pairs in trainset and labeled 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('film', 0.6140520572662354),\n",
       " ('spielberg', 0.43539032340049744),\n",
       " ('console', 0.4009501338005066),\n",
       " ('sylvester', 0.3827870786190033),\n",
       " ('animate', 0.3810267746448517),\n",
       " ('tv', 0.37869757413864136),\n",
       " ('entertainment', 0.37179452180862427),\n",
       " ('stallone', 0.36797311902046204),\n",
       " ('tudio', 0.3666054904460907),\n",
       " ('television', 0.3636029362678528)]"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(['movie'], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def prepare_relevance_data(N):\n",
    "    file = json.load(open(train_set))\n",
    "    query = [x['question'] for x in file]\n",
    "    answer = [x['text'] for x in file]\n",
    "\n",
    "    pair = []\n",
    "    for i in range(N):\n",
    "        q = query[i]\n",
    "        a = answer[i]\n",
    "        pair.append(((q,a),1))\n",
    "        random_q = random_a = [i]\n",
    "    \n",
    "        while random_q[0] == i:\n",
    "            random_q = np.random.choice(N,1)\n",
    "        while random_a[0] == i or random_a[0] == random_q[0]:\n",
    "            random_a = np.random.choice(N,1)\n",
    "        q = query[random_q[0]]  \n",
    "        a = answer[random_a[0]]\n",
    "        pair.append(((q,a),0))\n",
    "    return pair\n",
    "\n",
    "trainset = prepare_relevance_data(40000)\n",
    "devset = prepare_relevance_data(3097)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_query(query,answer):\n",
    "    q = [x.lower().strip('?') for x in query.split()]\n",
    "    trans_form_query = []\n",
    "    for word in q:\n",
    "        if word == 'what' or \\\n",
    "        word == 'who' or \\\n",
    "        word == 'where' or \\\n",
    "        word == 'when' or \\\n",
    "        word == 'which'or \\\n",
    "        word == 'how'or \\\n",
    "        word == 'whose':\n",
    "            word = str(answer)\n",
    "        trans_form_query.append(word)\n",
    "    q = ' '.join(trans_form_query)\n",
    "    return q    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#just a demo, need more pre-extracted potential answer sets\n",
    "\n",
    "import ast\n",
    "def prepare_train(N,dataset):\n",
    "    file = json.load(open(dataset))\n",
    "    f = open(log_file,\"r\")\n",
    "    corrects = []\n",
    "    wrongs = []\n",
    "    for i,tops in enumerate(f):\n",
    "        line = file[i]\n",
    "        query = line['question']\n",
    "        answer = line['text']\n",
    "        correct = transform_query(query,answer)\n",
    "        corrects.append(correct)\n",
    "        topk = ast.literal_eval(tops.strip())\n",
    "        constituents = get_para_constituent(topk)\n",
    "        for n in range(5):\n",
    "            cons = np.random.choice(constituents,1)\n",
    "            wrong = transform_query(query, cons[0])\n",
    "            wrongs.append(wrong)\n",
    "    return corrects, wrongs\n",
    "\n",
    "correct, wrong = prepare_train(4155,train_set)\n",
    "label = []\n",
    "\n",
    "for i in correct:\n",
    "    label.append(1)\n",
    "for i in wrong:\n",
    "    label.append(0)\n",
    "    \n",
    "print(\"done\")\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(len(correct))\n",
    "print(len(wrong))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def prepare_feature_vector(correct,wrong):\n",
    "    matrix = []\n",
    "    for i in correct:\n",
    "        vector = sent2vec(i, model, 160, index2word_set,'disable')\n",
    "        matrix.append(vector)\n",
    "    for i in wrong:\n",
    "        vector = sent2vec(i, model, 160, index2word_set,'disable')\n",
    "        matrix.append(vector)\n",
    "    return matrix\n",
    "\n",
    "X = prepare_feature_vector(correct,wrong)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(len(X))\n",
    "print(len(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- binary task, long feature vector -> take SVM classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def train(X,y):   \n",
    "    model = LogisticRegression()\n",
    "    best_model = model.fit(X, y)\n",
    "    return best_model\n",
    "            \n",
    "relevance_model = train(X,label)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def pred(query,entity,classifier):\n",
    "    \n",
    "    q = transform_query(query,entity)\n",
    "    vector = sent2vec(q, model, 160, index2word_set,'disable')\n",
    "    preds = classifier.predict([vector][0:])\n",
    "    return preds\n",
    "    \n",
    "pred = pred(\"What example is given as another paired relationship of uncertainly related to standard deviation?\",\n",
    "            \"time vs. energy\",\n",
    "           relevance_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "q = []\n",
    "l = []\n",
    "for i in range(4741):\n",
    "    q.append(sent2vec(wrong[i], model, 160, index2word_set,'disable'))\n",
    "    l.append(0)\n",
    "for i in correct:\n",
    "    q.append(sent2vec(i, model, 160, index2word_set,'disable'))\n",
    "    l.append(1)\n",
    "    \n",
    "preds = relevance_model.predict(q[0:])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from sklearn.externals import joblib\n",
    "\n",
    "#save clf\n",
    "joblib.dump(relevance_model, '/Users/alfredchen/Documents/GitHub/query-system/models/relevance.pkl')\n",
    "\n",
    "#load clf\n",
    "#relevance_model = joblib.load('/Users/alfredchen/Documents/GitHub/query-system/models/relevance.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def relevant(query, answer, classifier):\n",
    "    X = []\n",
    "    for i in range(len(query)):\n",
    "        q = transform_query(query[i],answer[i])\n",
    "          \n",
    "        x = sent2vec(q, model, 160, index2word_set,'disable')\n",
    "        #x = np.concatenate((q,a),axis=0)\n",
    "        X.append(x)\n",
    "    preds=relevance_model.predict(X[0:])\n",
    "    return preds\n",
    "\n",
    "#dev set\n",
    "\n",
    "query=[]\n",
    "answer = []\n",
    "labels = []\n",
    "for pair,label in devset:\n",
    "    query.append(pair[0])\n",
    "    answer.append(pair[1])\n",
    "    labels.append(label)\n",
    "    \n",
    "preds = relevant(query,answer,relevance_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def print_metrices(y_test,y_pred):\n",
    "    print(\"Accuracy:\")\n",
    "    print(metrics.accuracy_score(y_test,y_pred))\n",
    "\n",
    "    print(\"\\nAverage precision:\")\n",
    "    print(metrics.precision_score(y_test,y_pred,average='macro'))\n",
    "\n",
    "    print(\"\\nAverage recall:\")\n",
    "    print(metrics.recall_score(y_test,y_pred,average='macro'))\n",
    "    \n",
    "    print(\"\\nAverage f1:\")\n",
    "    print(metrics.f1_score(y_test,y_pred,average='macro'))\n",
    "\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    \n",
    "print_metrices(l, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def keywords_extraction(query):\n",
    "    query = query.split(' ')\n",
    "    query = [removePunc(x) for x in query]\n",
    "    query = [lemmatize(x.lower()) for x in query]\n",
    "    q = []\n",
    "    for w in query:\n",
    "        if not stopwords.get(w) and w != '':\n",
    "            q.append(w)\n",
    "    print(q)\n",
    "    tagged = nltk.pos_tag(q,tagset=\"universal\")\n",
    "    return [p[0] for p in tagged if p[1] in [\"ADJ\",\"NOUN\",\"VERB\",\"NUM\"]]\n",
    "\n",
    "\n",
    "def relation_extraction(query):\n",
    "    words = keywords_extraction(query)\n",
    "    if words == []:\n",
    "        return\n",
    "    relations = defaultdict(dict)\n",
    "    for w1 in words:\n",
    "        for w2 in words:\n",
    "            if w1 == w2:\n",
    "                continue\n",
    "            else:\n",
    "                relations[w1][w2] = relations[w1].get(w2, 0) + 1\n",
    "    return relations\n",
    "\n",
    "pos = keywords_extraction(\"a kilogram can be defined as what value\")\n",
    "print(pos)\n",
    "relations = relation_extraction(\"a kilogram can be defined as what value?\")\n",
    "print(relations)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def answer_type(query):\n",
    "    query = query.split()\n",
    "    query = [removePunc(x) for x in query]\n",
    "    query = [lemmatize(x.lower()) for x in query]\n",
    "    for word in query:\n",
    "        if word == 'what':\n",
    "            return 'O'\n",
    "        elif word == 'who':\n",
    "            return 'PERSON'\n",
    "        elif word == 'where':\n",
    "            return 'LOCATION'\n",
    "        elif word == 'when':\n",
    "            return 'DATE'\n",
    "        elif word == 'which':\n",
    "            return 'O'\n",
    "    return 'O'\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# three round to extract a list of potential answers from topk paragraphs\n",
    "\n",
    "    - PERSON                -People, including fictional.\n",
    "    - NORP\t              -Nationalities or religious or political groups.\n",
    "    - FACILITY\t          -Buildings, airports, highways, bridges, etc.\n",
    "    - ORG\t                  -Companies, agencies, institutions, etc.\n",
    "    - GPE\t                  -Countries, cities, states.\n",
    "    - LOC\t                  -Non-GPE locations, mountain ranges, bodies of water.\n",
    "    - PRODUCT\t              -Objects, vehicles, foods, etc. (Not services.)\n",
    "    - EVENT\t              -Named hurricanes, battles, wars, sports events, etc.\n",
    "    - WORK_OF_ART\t          -Titles of books, songs, etc.\n",
    "    - LAW\tNamed             -documents made into laws.\n",
    "    - LANGUAGE\t          -Any named language.\n",
    "    - DATE\t              -Absolute or relative dates or periods.\n",
    "    - TIME\t              -Times smaller than a day.\n",
    "    - PERCENT\t              -Percentage, including \"%\".\n",
    "    - MONEY\t              -Monetary values, including unit.\n",
    "    - QUANTITY\t          -Measurements, as of weight or distance.\n",
    "    - ORDINAL\t              -\"first\", \"second\", etc.\n",
    "    - CARDINAL\t          -Numerals that do not fall under another type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up classifier for detect answer type\n",
    "def detect_answer_type(query):\n",
    "    return answer_type\n",
    "\n",
    "#preprocess word in query\n",
    "def preprocess_sentence(sentence):\n",
    "    words = sentence.split(' ')\n",
    "    words = [lemmatize(removePunc(x.lower())) for x in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "def named_entity_recognize(sentence,valid_ner):\n",
    "    #do not preprocess sentence when getting named entity using spacy\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    entities = []\n",
    "    ner_tag = []\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(sentence)\n",
    "    if valid_ner == 'disable':\n",
    "        ner_tag = ''\n",
    "        for ent in doc.ents:\n",
    "            ner_tag=ent.label_\n",
    "        if ner_tag == '':\n",
    "            ner_tag = 'O'\n",
    "        return ner_tag\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in valid_ner:\n",
    "            entities.append(ent)\n",
    "            ner_tag.append(ent.label_)\n",
    "    # case 'O'\n",
    "    if valid_ner == 'O':\n",
    "        sentence = preprocess_sentence(sentence)\n",
    "        ents = sentence.split(' ')\n",
    "        \n",
    "        \"\"\"\n",
    "        add more selection method\n",
    "        \"\"\"\n",
    "        entities += ents\n",
    "        ner_tag.append('O')\n",
    "        if entities == []:\n",
    "            return 'unknown'\n",
    "    return entities\n",
    "\n",
    "entities = named_entity_recognize(\"January 11, 2017\",['DATE','TIME','CARDINAL','GPE'])  \n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply ner recognition to get all answer type from training data\n",
    "\"\"\"\n",
    "def tag_answer(dataset):\n",
    "    file = json.load(open(dataset))\n",
    "    for _id,line in enumerate(file):\n",
    "        answer = line['text']\n",
    "        label = named_entity_recognize(answer,'disable')\n",
    "        f = open(answer_type,\"a\")\n",
    "        f.write(str(_id)+':'+str(label)+'\\n')\n",
    "        f.close()\n",
    "    print('done')\n",
    "    return True\n",
    "\n",
    "tag_answer(train_set)\n",
    "\"\"\" \n",
    "pass\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18174\n",
      "18174\n"
     ]
    }
   ],
   "source": [
    "# train a classifier to recognize answer type from query using top 18173 data)\n",
    "\n",
    "def rule(sentence):\n",
    "    sentence = preprocess_sentence(sentence).split(' ')\n",
    "    rule = {\n",
    "        'person':'PERSON',\n",
    "        'location': 'GPE',            \n",
    "        'who': 'PERSON',\n",
    "        'why': 'O',\n",
    "        'from': 'GPE',\n",
    "        'country': 'GPE',\n",
    "        'capital': 'GPE',\n",
    "        'city': 'GPE',\n",
    "        'when': 'DATE',\n",
    "        'many': 'CARDINAL',\n",
    "        'long':'CARDINAL',\n",
    "        'high': 'CARDINAL',\n",
    "        'year': 'DATE',\n",
    "        'decade': 'CARDINAL',\n",
    "        'time': 'DATE',\n",
    "        'cost': 'MONEY',\n",
    "        'population': 'CARDINAL',\n",
    "        'number':'CARDINAL'\n",
    "    }\n",
    "    for word in sentence:\n",
    "        if rule.get(word):\n",
    "            return rule.get(word)\n",
    "    return 'O'\n",
    "\n",
    "def query2vector(dataset):\n",
    "    \n",
    "    label =  open(answer_type_file)\n",
    "    train = json.load(open(dataset))\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i,line in enumerate(label):\n",
    "        x = sent2vec(train[i]['question'], model, 160, index2word_set, 'disable')\n",
    "        y = line.split(':')[1].strip()\n",
    "        if y == 'O':\n",
    "            y=rule(train[i]['question'])\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    label.close()\n",
    "    return X,Y\n",
    "    \n",
    "vectors,labels = query2vector(train_set)\n",
    "print(len(vectors))\n",
    "print(len(labels))\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# logistic classifier\n",
    "def train(X,y):   \n",
    "    clf = LogisticRegression()\n",
    "    best_model = clf.fit(X, y)\n",
    "    return best_model\n",
    "            \n",
    "answer_type = train(vectors,labels)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONEY\n"
     ]
    }
   ],
   "source": [
    "def pred_answer_type(query,classifier):\n",
    "    q = sent2vec(query, model, 160, index2word_set, 'disable')\n",
    "    preds = classifier.predict([q][0:])\n",
    "    return preds[0]\n",
    "\n",
    "print(pred('how much do you spend',answer_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assumptions\n",
    "\n",
    "        1. answers are not in the query and are not stopwords\n",
    "        2. answers are semantically close to query keywords\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "import math\n",
    "\n",
    "def cosine_similarity(v1: np.ndarray, v2: np.ndarray) -> float:\n",
    "    \"\"\"https://en.wikipedia.org/wiki/Cosine_similarity\"\"\"\n",
    "    num = np.dot(v1, v2)\n",
    "    d1 = np.dot(v1, v1)\n",
    "    d2 = np.dot(v2, v2)\n",
    "    if d1 > 0.0 and d2 > 0.0:\n",
    "        return num / math.sqrt(d1 * d2)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "\n",
    "stop_words = get_stopwords(False) \n",
    "def first_filter(query,answer):\n",
    "    \"\"\"\n",
    "    remove stopwords in answers\n",
    "    remove duplicate answers\n",
    "    remove words in query\n",
    "    \"\"\"\n",
    "    query = preprocess_sentence(query).split(' ')\n",
    "    q = []\n",
    "    a = []\n",
    "    template = []\n",
    "    for w in query:\n",
    "        if not stop_words.get(w):\n",
    "            q.append(w)\n",
    "    for w in answer:\n",
    "        try:\n",
    "            flag = 1\n",
    "            words = str(w.text).split(' ')\n",
    "            words = [lemmatize(removePunc(x).lower()) for x in words]\n",
    "            for word in words:\n",
    "                if not stop_words.get(word):\n",
    "                    if word not in template:\n",
    "                        if word in q:\n",
    "                            flag = 0\n",
    "                    else:\n",
    "                        flag = 0\n",
    "                else:\n",
    "                    flag = 0\n",
    "            if flag == 1:\n",
    "                a.append(w.text)\n",
    "                template += words\n",
    "        except AttributeError:\n",
    "            word = lemmatize(w.lower())\n",
    "            if not stop_words.get(word):\n",
    "                if word not in template:\n",
    "                    if word not in q:\n",
    "                        a.append(w)\n",
    "                        template.append(word)\n",
    "    q = ' '.join(q)\n",
    "    return q,a\n",
    "\n",
    "def second_filter(query,answer):\n",
    "    \"\"\"\n",
    "    the most potential answer is semantically most similar to query\n",
    "    \"\"\"\n",
    "    query, answer = first_filter(query,answer)\n",
    "    query_semantic = sent2vec(query, model, 160, index2word_set, 'disable')\n",
    "    max_sim = 1\n",
    "    potential_answer = ''\n",
    "    for a in answer:\n",
    "        tmp = lemmatize(a.lower())\n",
    "        ans = sent2vec(a, model, 160, index2word_set, 'disable')\n",
    "        sim = cosine_similarity(query_semantic,ans)\n",
    "        if sim > 0:\n",
    "            return a\n",
    "            print(a)\n",
    "            max_sim = sim\n",
    "            potential_answer = a\n",
    "    return potential_answer\n",
    "            \n",
    "        \n",
    "    \n",
    "\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London\n"
     ]
    }
   ],
   "source": [
    "def extract_answer_from_topk(query,topk):\n",
    "    context = \"\"\n",
    "    for index in topk:\n",
    "        context += index2para.get(tuple(index))\n",
    "    valid_ner = pred_answer_type(query,answer_type)\n",
    "    if valid_ner == 'O':\n",
    "        valid_ner = rule(query)\n",
    "    potential_answers = named_entity_recognize(context,valid_ner)\n",
    "    answer = second_filter(query,potential_answers)\n",
    "    return answer\n",
    "\n",
    "topk = getTopN(10,\"what is the capital of England?\",'disable')\n",
    "query = \"what is the capital of England?\"\n",
    "\n",
    "answers = extract_answer_from_topk(query,topk)\n",
    "print(answers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0392156862745098\n",
      "0.04950495049504951\n",
      "0.039735099337748346\n",
      "0.029850746268656716\n",
      "0.043824701195219126\n",
      "0.04318936877076412\n",
      "0.039886039886039885\n",
      "0.0399002493765586\n",
      "0.037694013303769404\n",
      "0.03992015968063872\n",
      "0.039927404718693285\n",
      "0.036605657237936774\n",
      "0.03533026113671275\n",
      "0.03281027104136947\n",
      "0.033288948069241014\n",
      "0.031210986267166042\n",
      "0.03407755581668625\n",
      "0.03440621531631521\n",
      "0.03680336487907466\n",
      "0.03896103896103896\n",
      "0.037107516650808754\n",
      "0.03814713896457766\n",
      "0.03735881841876629\n",
      "0.03746877601998335\n",
      "0.037569944044764186\n",
      "0.03766333589546503\n",
      "0.03626943005181347\n",
      "0.03568879371877231\n",
      "0.03583735354927636\n",
      "0.03530979347101932\n",
      "0.03481624758220503\n",
      "0.03560274828232355\n",
      "0.03513022410660206\n",
      "0.03409758965314521\n",
      "0.03312392918332382\n",
      "0.03220433092726263\n",
      "0.031334413830361965\n",
      "0.03103629668595476\n",
      "0.03177857508969759\n",
      "0.031984007996002\n",
      "0.031204290589956118\n",
      "0.03236554021894336\n",
      "0.03161320316132032\n",
      "0.03225806451612903\n",
      "0.03198578409595735\n",
      "0.03129074315514994\n",
      "0.03317737133134836\n",
      "0.03373594335693461\n",
      "0.03345573235414117\n",
      "0.03318672530987605\n",
      "0.03410427283418267\n",
      "0.03383314109957709\n",
      "0.03319502074688797\n",
      "0.03295075897815624\n",
      "0.03307888040712468\n",
      "0.03248839700107105\n",
      "0.03262013328656612\n",
      "0.03274732850741124\n",
      "0.03287021348695358\n",
      "0.032989003665444855\n",
      "0.03310390036053753\n"
     ]
    }
   ],
   "source": [
    "# test acc on devset\n",
    "def test_answers(dataset):\n",
    "    file = json.load(open(dataset))\n",
    "    #top_k = open(topk_file)\n",
    "    gold = []\n",
    "    pred = []\n",
    "    for _id,line in enumerate(file):\n",
    "        query = line['question']\n",
    "        topk = getTopN(10,query,line['docid'])\n",
    "        answer = extract_answer_from_topk(query,topk)\n",
    "        gold.append(line['text'])\n",
    "        pred.append(answer)\n",
    "        if _id % 50 == 0:\n",
    "            print(metrics.accuracy_score(gold,pred))\n",
    "            \n",
    "    return gold,pred\n",
    "\n",
    "gold,pred = test_answers(dev_set)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrices(y_test,y_pred): \n",
    "    print(\"Accuracy:\") \n",
    "    print(metrics.accuracy_score(y_test,y_pred))\n",
    "    \n",
    "    print(\"\\nAverage precision:\")\n",
    "    print(metrics.precision_score(y_test,y_pred,average='macro'))\n",
    "\n",
    "    print(\"\\nAverage recall:\")\n",
    "    print(metrics.recall_score(y_test,y_pred,average='macro'))\n",
    "\n",
    "    print(\"\\nAverage f1:\")\n",
    "    print(metrics.f1_score(y_test,y_pred,average='macro'))\n",
    "\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "print_metrices(gold, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
